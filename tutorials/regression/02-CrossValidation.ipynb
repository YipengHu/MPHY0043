{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QAYbcwQ0FQI9"
   },
   "source": [
    "# 2 Linear Regression - Cross Validation (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-EdWwbU1FQJB"
   },
   "source": [
    "## 2.1 Utility Functions\n",
    "Rewrite the code in the previous tutorial as functions, and expand them to *deg* degree with *deg+1* terms.\n",
    "- *polynomial_evaluate(x,w)* evaluates the polynomial function (defined by the weights $w$) at $x$ locations.\n",
    "- *polynomial_fit(x,deg)* fits a new polynomial (defined by $w$) with a fixed (highest) degree *deg*, to the given data pairs [$x$, $t$].\n",
    "- *polynomial_basis(x,deg)* constructs terms of polynomial function of given $x$ with a degree of *deg*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# functions based on the previous tutorial\n",
    "def polynomial_evaluate(x, w):\n",
    "    X = polynomial_basis(x, w.size-1)\n",
    "    t = np.matmul(X, w)\n",
    "    return t\n",
    "\n",
    "def polynomial_fit(x, t, deg):\n",
    "    X = polynomial_basis(x, deg)\n",
    "    w = np.linalg.lstsq(X, t, rcond=None)\n",
    "    return w[0]\n",
    "\n",
    "def polynomial_basis(x, deg):\n",
    "    X = np.power(np.reshape(x,[-1,1]), np.linspace(deg,0,deg+1))\n",
    "    return X\n",
    "\n",
    "def rms_error(residuals):\n",
    "    return np.sqrt(np.mean(np.square(residuals)))\n",
    "\n",
    "\n",
    "# test\n",
    "X = polynomial_basis(np.array([.1,.2,.3,.4,.5]), 3)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data\n",
    "In this tutorial, the true model here is a polynomial with a degree of 4:\n",
    "\n",
    "\\begin{equation}\n",
    "t = w_3x^3 + w_2x^2 + w_1x +w_0\n",
    "\\end{equation}\n",
    "\n",
    "with weights $$\\textbf{w}=\\begin{vmatrix}4 & 3 & 2 & 1\\end{vmatrix}^T$$\n",
    "\n",
    "*n* observed data are sampled as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "w = np.reshape([4, 3, 2, 1], [-1, 1])\n",
    "\n",
    "# sample locations\n",
    "n = 50\n",
    "x = np.linspace(-1,1,n)\n",
    "\n",
    "# observed target data\n",
    "std_noise = 0.5\n",
    "t = polynomial_evaluate(x, w)\n",
    "t_observed = t + np.random.normal(0,std_noise,[n,1])\n",
    "\n",
    "# plot\n",
    "plt.plot(x,t,'r')\n",
    "plt.plot(x,t_observed,'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, sample *n_holdout* holdout data that will not be used to fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdout (also observed) data\n",
    "n_holdout = 30\n",
    "x_holdout = np.linspace(-1,1,n_holdout)\n",
    "t_holdout = polynomial_evaluate(x_holdout, w) + np.random.normal(0,std_noise,[n_holdout,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Underfitting and Overfitting\n",
    "First, try to fit the following polynomial models, the first of which is a straight line:\n",
    "\n",
    "\\begin{equation}\n",
    "t_{deg=1} = w_1x + w_0\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "t_{deg=2} = w_2x^2 + w_1x + w_0\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "t_{deg=3} = w_3x^3 + w_2x^2 + w_1x + w_0\n",
    "\\end{equation}\n",
    "\n",
    "$$\\cdots$$\n",
    "\n",
    "\\begin{equation}\n",
    "t_{deg=m} = w_mx^m + \\cdots + w_3x^3 + w_2x^2 + w_1x + w_0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, fit the polynomials\n",
    "degrees = [1,2,3,4,5,10,20,30]  # examples of degrees\n",
    "w_estimates = []\n",
    "t_estimates = []\n",
    "for idx in range(len(degrees)):\n",
    "    w_estimates.append(polynomial_fit(x, t_observed, deg=degrees[idx]))\n",
    "    t_estimates.append(polynomial_evaluate(x, w_estimates[idx]))\n",
    "    \n",
    "    # residuals and root-mean-square errors\n",
    "    Residuals = t_estimates[idx]-t_observed\n",
    "    SR = np.sum(np.square(Residuals))\n",
    "    RMSE = rms_error(Residuals)\n",
    "    print([degrees[idx],SR,RMSE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot each fitted curve to compare, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = degrees.index(1)\n",
    "plt.plot(x,t,'r')\n",
    "plt.plot(x,t_observed,'bo')\n",
    "plt.plot(x,t_estimates[idx],'g')\n",
    "\n",
    "plt.figure()\n",
    "idx = degrees.index(30)\n",
    "plt.plot(x,t,'r')\n",
    "plt.plot(x,t_observed,'bo')\n",
    "plt.plot(x,t_estimates[idx],'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 K-fold Cross-validation\n",
    "K-fold cross-validation splits the original sample into k equal-sized subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k âˆ’ 1 subsamples are used as training data. The training-testing process is then repeated k times, with each of the k subsamples used exactly once as the validation data. The k results can then be averaged to produce an estimation of the model performance.\n",
    "\n",
    "It is of great importance to understand the difference between training- and testing errors. Conceptually, the training error is to summarise the residuals between the fitted-model predicted targets and the observed ones which have been used for fitting the model, whilst the testing error is the difference based on an independent set of data that have been *unseen* to the model fitting process, which estimates the optimal model weights. The concept of \"unseen\" is also useful in distinguishing different types of errors in cross-validation experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# shuffle data first\n",
    "indices = [idx for idx in range(n)]\n",
    "random.seed(1)\n",
    "random.shuffle(indices)\n",
    "\n",
    "# set up a 5-fold cross-validation\n",
    "k = 5\n",
    "size_fold = int(n/k)\n",
    "deg = 4  # model to fit\n",
    "\n",
    "Residuals_train = []\n",
    "Residuals_test = []\n",
    "for idx_fold in range(k):  # fold index\n",
    "    # set indices for training data and test data\n",
    "    indices_test = indices[idx_fold*size_fold:(idx_fold+1)*size_fold]\n",
    "    indices_train = list(set(indices) - set(indices_test))\n",
    "    \n",
    "    # training    \n",
    "    w_train = polynomial_fit(x[indices_train], t_observed[indices_train], deg=deg)\n",
    "    t_train = polynomial_evaluate(x[indices_train], w_train)    \n",
    "    Residuals_train.append(t_train-t_observed[indices_train])\n",
    "    # testing\n",
    "    t_test = polynomial_evaluate(x[indices_test], w_train)\n",
    "    Residuals_test.append(t_test-t_observed[indices_test])\n",
    "\n",
    "# calculating training and testing errors\n",
    "RMSE_train = rms_error(np.concatenate(Residuals_train, axis=0))\n",
    "RMSE_test = rms_error(np.concatenate(Residuals_test, axis=0))\n",
    "print(RMSE_train) \n",
    "print(RMSE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "- Find an optimal degree with respect to the testing error.\n",
    "- What can reduce training error and/or testing error?\n",
    "- Given a fixed set of observed data, is it possible to find a polynomial that produces smaller testing error than the underlying \"true\" model?\n",
    "- What is the difference between an overfitted polynomial model and an overfitted cross-validation model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Generalisability\n",
    "Different from the testing error obtained in each fold, a better estimate of the generalisation ability can be quantified by the testing error on holdout data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model using all the data and the selected (optimised) hyperparameter degree\n",
    "deg = 4\n",
    "w_train = polynomial_fit(x, t_observed, deg=deg)\n",
    "t_train = polynomial_evaluate(x, w_train)\n",
    "RMSE_train = rms_error(t_train-t_observed)\n",
    "t_test = polynomial_evaluate(x_holdout, w_train)\n",
    "RMSE_test = rms_error(t_test-t_holdout)\n",
    "print(RMSE_train) \n",
    "print(RMSE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "- Adding norm-2 regularisation to the model fitting, does this help?\n",
    "- What is the required data size for training and testing. How are training and testing errors affected by the data size? \n",
    "- Compare testing errors in cross-validation and those based on holdout data. Under what conditions, they are different?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tutorials_02-CrossValidation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

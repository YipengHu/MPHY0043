{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpAWjuE0zX__"
   },
   "source": [
    "# 2D XRay registration demo\n",
    "This demo is a toy example showing the usage of MONAI's registration capability.\n",
    "\n",
    "The demo mainly uses\n",
    "- a UNet-like registration network with an affine head to predict the affine transformation parameters;\n",
    "- a warp function, implemented as a MONAI C++/CUDA module, is used to transform the moving image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lI6G5tLMzqUM"
   },
   "source": [
    "## Setup environment\n",
    "\n",
    "Please set up the environment by following the [module documentation](https://github.com/YipengHu/MPHY0043/blob/main/docs/dev_tools.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSGmeSK8zy4C"
   },
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a4y9P06TzmR",
    "outputId": "6fe774bd-5dc7-4047-ccdd-d738b32ddd06"
   },
   "outputs": [],
   "source": [
    "from monai.utils import set_determinism, first\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstD,\n",
    "    Compose,\n",
    "    LoadImageD,\n",
    "    RandRotateD,\n",
    "    RandZoomD,\n",
    "    ScaleIntensityRanged,\n",
    "    ToTensorD,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.config import print_config\n",
    "from monai.networks.nets import GlobalNet\n",
    "from monai.networks.blocks import Warp\n",
    "from monai.apps import MedNISTDataset\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import L1Loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print_config()\n",
    "set_determinism(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEdRdq0NUQj_"
   },
   "source": [
    "# Construct pairwise training inputs\n",
    "We use the `MedNISTDataset` object to download and unzip the actual data files.\n",
    "Then we select the hand class, convert the loaded data dicts into \"fixed_hand\" and \"moving_hand\" which will be preprocessed differently to create synthetic training pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9KlURISUxcr",
    "outputId": "9b68e66d-1fbd-4773-d782-7f1d42aec643"
   },
   "outputs": [],
   "source": [
    "train_data = MedNISTDataset(root_dir=\"./\", section=\"training\", download=True, transform=None)\n",
    "training_datadict = [\n",
    "    {\"fixed_hand\": item[\"image\"], \"moving_hand\": item[\"image\"]}\n",
    "    for item in train_data.data if item[\"label\"] == 4  # label 4 is for xray hands\n",
    "]\n",
    "print(\"\\n first training items: \", training_datadict[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZJCeerKTu3s"
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImageD(keys=[\"fixed_hand\", \"moving_hand\"]),\n",
    "        EnsureChannelFirstD(keys=[\"fixed_hand\", \"moving_hand\"]),\n",
    "        ScaleIntensityRanged(keys=[\"fixed_hand\", \"moving_hand\"],\n",
    "                             a_min=0., a_max=255., b_min=0.0, b_max=1.0, clip=True,),\n",
    "        RandRotateD(keys=[\"moving_hand\"], range_x=np.pi/4, prob=1.0, keep_size=True, mode=\"bilinear\"),\n",
    "        RandZoomD(keys=[\"moving_hand\"], min_zoom=0.9, max_zoom=1.1, prob=1.0, mode=\"bilinear\", align_corners=False),\n",
    "        ToTensorD(keys=[\"fixed_hand\", \"moving_hand\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUKGXidL2ViQ"
   },
   "source": [
    "## Visualisation of the training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "LzFV9LY8VXy1",
    "outputId": "c13d8dc3-a7f6-4d3a-e186-2b6f91b6be0f"
   },
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=training_datadict, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1, shuffle=True)\n",
    "check_data = first(check_loader)\n",
    "fixed_image = check_data[\"fixed_hand\"][0][0]\n",
    "moving_image = check_data[\"moving_hand\"][0][0]\n",
    "\n",
    "print(f\"moving_image shape: {moving_image.shape}\")\n",
    "print(f\"fixed_image shape: {fixed_image.shape}\")\n",
    "\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"moving_image\")\n",
    "plt.imshow(moving_image, cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"fixed_image\")\n",
    "plt.imshow(fixed_image, cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwO0Q3Hg2hOJ"
   },
   "source": [
    "## Create the training pipelines\n",
    "We use a CacheDataset to accelerate the training process.\n",
    "The training data are fed into a `GlobalNet` which predicts image-level affine transformation parameters. A `Warp` layer is initialised and will be used for both training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjSwFJJvW7Qc",
    "outputId": "33fa06d7-8124-45fd-a6f1-c5809f8f80b9"
   },
   "outputs": [],
   "source": [
    "train_ds = CacheDataset(data=training_datadict[:1000], transform=train_transforms,\n",
    "                        cache_rate=1.0, num_workers=4)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHAj8nuHXG-D"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = GlobalNet(\n",
    "    image_size=(64, 64),\n",
    "    spatial_dims=2,\n",
    "    in_channels=2,  # moving and fixed\n",
    "    num_channel_initial=16,\n",
    "    depth=3).to(device)\n",
    "image_loss = L1Loss()\n",
    "warp_layer = Warp().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a7hoesI29m4"
   },
   "source": [
    "## The training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyiL4ccmYsjt",
    "outputId": "5abda54f-ff48-49a2-bd36-aed217cbf491"
   },
   "outputs": [],
   "source": [
    "epoch_num = 200\n",
    "epoch_loss_values = []\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    epoch_loss, step = 0, 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        moving = batch_data[\"moving_hand\"].to(device)\n",
    "        fixed = batch_data[\"fixed_hand\"].to(device)\n",
    "        ddf = model(torch.cat((moving, fixed), dim=1))\n",
    "        pred_image = warp_layer(moving, ddf)\n",
    "\n",
    "        loss = image_loss(pred_image, fixed)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        # print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "        #       f\"train_loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "hZYvG_oE32-9",
    "outputId": "5c45a47e-18e9-43b7-881d-51fdef889059"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(epoch_loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEfFYtwgqy6i"
   },
   "source": [
    "# Visualise some validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qgxi6nsQn1om",
    "outputId": "9aa630b3-5c0b-4e33-eba4-7f9ed6f967b4"
   },
   "outputs": [],
   "source": [
    "val_ds = CacheDataset(data=training_datadict[2000:2500], transform=train_transforms,\n",
    "                      cache_rate=1.0, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, num_workers=0)\n",
    "for batch_data in val_loader:\n",
    "    moving = batch_data[\"moving_hand\"].to(device)\n",
    "    fixed = batch_data[\"fixed_hand\"].to(device)\n",
    "    ddf = model(torch.cat((moving, fixed), dim=1))\n",
    "    pred_image = warp_layer(moving, ddf)\n",
    "    break\n",
    "\n",
    "fixed_image = fixed.detach().cpu().numpy()[:, 0]\n",
    "moving_image = moving.detach().cpu().numpy()[:, 0]\n",
    "pred_image = pred_image.detach().cpu().numpy()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "Sz-lwwv-oIZ6",
    "outputId": "2604e7b6-ddc8-4d39-fa6c-9725a969a202"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "batch_size = 5\n",
    "plt.subplots(batch_size, 3, figsize=(8, 10))\n",
    "for b in range(batch_size):\n",
    "    # moving image\n",
    "    plt.subplot(batch_size, 3, b * 3 + 1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"moving image\")\n",
    "    plt.imshow(moving_image[b], cmap=\"gray\")\n",
    "    # fixed image\n",
    "    plt.subplot(batch_size, 3, b * 3 + 2)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"fixed image\")\n",
    "    plt.imshow(fixed_image[b], cmap=\"gray\")\n",
    "    # warped moving\n",
    "    plt.subplot(batch_size, 3, b * 3 + 3)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"registered image\")\n",
    "    plt.imshow(pred_image[b], cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "registration_simple.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
